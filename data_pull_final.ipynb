{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Identification Module - Web Parsing*\n",
    "This is the Identification Module that pulls data from selected resources on the internet and writes them to CSV files in the data folder.\n",
    "\n",
    "The data assessment module will then use this data for assessment and provide a JSON output..\n",
    "\n",
    "**NOTE**: Some sources have threats that have already been assessed so will directly give an output skipping the assessment stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "import csv\n",
    "import tweepy\n",
    "import re\n",
    "import json\n",
    "import bs4\n",
    "import pandas as pd\n",
    "import requests\n",
    "from urllib.request import urlopen as uReq\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from datetime import datetime, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUrls():\n",
    "    url = []\n",
    "    url.append('https://www.cyber.gov.au/acsc/view-all-content/alerts')\n",
    "    url.append('https://www.smh.com.au/topic/nsw-police-jdi')\n",
    "    url.append('https://www.smh.com.au/topic/sydney-crime-62n')\n",
    "    url.append('https://www.smh.com.au/topic/crime-5w4')\n",
    "    url.append('https://www.smh.com.au/topic/australian-federal-police-jnt')\n",
    "    url.append('https://www.9news.com.au/cyber-security')\n",
    "    url.append('https://www.9news.com.au/security')\n",
    "    url.append('https://www.rapid7.com/db/?q=&type=nexpose')\n",
    "    url.append('https://www.rapid7.com/db/?q=&type=nexpose&page=2')\n",
    "    url.append('https://www.rapid7.com/db/?q=&type=nexpose&page=3')\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the html data from the url to p_html\n",
    "def urlReq(my_url):\n",
    "    uClient = uReq(my_url)\n",
    "    p_html = uClient.read()\n",
    "    uClient.close()\n",
    "    return soup(p_html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cga(parsed_html):\n",
    "    #Splitting the html into a list of threats\n",
    "    articles = parsed_html.findAll(\"div\", {\"class\":\"views-row\"})\n",
    "    #deleting unrequired row from the list\n",
    "    del articles[0]\n",
    "    #Creating .csv file in the data folder and writing the required information from the list to .csv file\n",
    "    with open('data/cyber_gov_au.csv', 'w') as file:\n",
    "        w = csv.writer(file)\n",
    "        #write header row\n",
    "        w.writerow(['Threat_date', 'Title', 'Threat_level', 'Summary', 'Source', 'Location'])\n",
    "        for article in articles:\n",
    "            dateS = article.find(\"p\", {\"class\":\"acsc-date\"}).get_text()\n",
    "            title = article.find(\"p\", {\"class\":\"acsc-title\"}).get_text()\n",
    "            summary = article.find(\"p\", {\"class\":\"acsc-summary\"}).get_text()\n",
    "            src_link = (\"https://www.cyber.gov.au\" + article.a['href'])\n",
    "\n",
    "            d = datetime.strptime(dateS, '%d %b %Y ')\n",
    "\n",
    "            uClient = uReq(src_link)\n",
    "            detailed_page = uClient.read()\n",
    "            uClient.close()\n",
    "            dp_parsed = soup(detailed_page, \"html.parser\")\n",
    "            Threat = dp_parsed.find(\"div\", {\"class\":\"field field--name-field-alert-status field--type-entity-reference field--label-inline\"})\n",
    "            lvl = Threat.find(\"div\", {\"class\":\"field__item\"}).get_text()\n",
    "\n",
    "            summary = summary.replace(\",\", \";\")\n",
    "            w.writerow([d.date(), title, lvl, summary, src_link, \"-\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smh(parsed_html, url):\n",
    "    articles = parsed_html.findAll(\"div\", {\"class\":\"_2g9tm\"})\n",
    "    #Creating csv file\n",
    "    fname = \"smh_\" + ('_'.join(re.findall(r\"(\\w+)\", url.rsplit('/', 1)[-1])))\n",
    "    with open ('data/%s.csv' % (fname), 'w') as file:\n",
    "        w = csv.writer(file)\n",
    "        \n",
    "    #Creating Headers for csv file \n",
    "        w.writerow(['Threat_date', 'Title', 'Threat_level', 'Summary', 'Source', 'Location'])\n",
    "\n",
    "    #grabbing news article information\n",
    "        for article in articles:\n",
    "            title = article.find(\"a\",{\"data-test\": \"article-link\"}).get_text()\n",
    "            summary = article.find(\"p\",{\"class\": \"_3b7W- _3XEsE\"}).get_text()\n",
    "            src_link = (\"https://www.smh.com.au\" + article.find(\"a\",{\"data-test\": \"article-link\"}).get('href'))\n",
    "            dateS = article.find(\"time\", {\"class\": \"_2_zR-\"}).get_text()\n",
    "            d = date.today()\n",
    "            if(\"Today\" in dateS):\n",
    "                w.writerow([d, title, 0,summary, url, \"-\"])\n",
    "            else:\n",
    "                d = datetime.strptime(dateS, '%B %d, %Y')\n",
    "                w.writerow([d.date(), title, 0,summary, src_link, \"-\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nine(parsed_html, url):\n",
    "    feed = parsed_html.find(\"div\", {\"data-feed\":\"default\"})\n",
    "    articles = feed.findAll(\"div\", {\"class\":\"story__details\"})\n",
    "    #Creating csv file\n",
    "    fname = \"9news_\" + ('_'.join(re.findall(r\"(\\w+)\", url.rsplit('/', 1)[-1])))\n",
    "    with open ('data/%s.csv' % (fname), 'w') as file:\n",
    "        w = csv.writer(file)\n",
    "        \n",
    "    #Creating Headers for csv file \n",
    "        w.writerow(['Threat_date', 'Title', 'Threat_level', 'Summary', 'Source', 'Location'])\n",
    "\n",
    "    #grabbing news article information\n",
    "        for article in articles:\n",
    "            if(article.find(\"div\",{\"class\": \"widget widget-ad feed__ad\"})):\n",
    "                pass\n",
    "            else:\n",
    "                title = article.find(\"span\",{\"class\": \"story__headline__text\"}).get_text()\n",
    "                summary = article.find(\"div\", {\"class\": \"story__abstract\"}).get_text()\n",
    "                src_link = article.a['href']\n",
    "                dateS = article.find(\"time\", {\"class\": \"story__time\"}).get_text()\n",
    "                d = date.today()\n",
    "                if(\"Today\" in dateS or \"ago\" in dateS):\n",
    "                    w.writerow([d, title, 0,summary, url, \"-\"])\n",
    "                else:\n",
    "                    d = datetime.strptime(dateS, '%I:%M%p %b %d, %Y')\n",
    "                    w.writerow([d.date(), title, 0,summary, src_link, \"-\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rapid(parsed_html, url):\n",
    "    articles = parsed_html.findAll(\"a\", {\"class\":\"vulndb__result resultblock\"})\n",
    "    #Creating csv file\n",
    "    fname = \"rapid7_\" + ('_'.join(re.findall(r\"(\\w+)\", url.rsplit(\"nexpose\", 1)[-1])))\n",
    "    with open ('data/%s.csv' % (fname), 'w') as file:\n",
    "        w = csv.writer(file)\n",
    "        \n",
    "    #Creating Headers for csv file \n",
    "        w.writerow(['Threat_date', 'Title', 'Threat_level', 'Summary', 'Source', 'Location'])\n",
    "\n",
    "    #grabbing news threat information\n",
    "        for article in articles:\n",
    "            title = article.find(\"div\",{\"class\": \"resultblock__info-title\"}).get_text()\n",
    "            src_link = (\"https://www.rapid7.com\" + article.get('href'))\n",
    "            meta = article.find(\"div\", {\"class\": \"resultblock__info-meta\"}).get_text()\n",
    "            meta = meta.lstrip().rstrip()\n",
    "            dateS = meta[11:30].rstrip()\n",
    "            lvl = int(meta[meta.find(\"Severity:\")+9:].split()[0].lstrip())\n",
    "            d = date.today()\n",
    "            if(\"Today\" in dateS):\n",
    "                w.writerow([d, title, 0,\"-\", url, \"-\"])\n",
    "            else:\n",
    "                d = datetime.strptime(dateS, '%B %d, %Y')\n",
    "                w.writerow([d.date(), title, lvl,\"-\", src_link, \"-\"])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.cyber.gov.au/acsc/view-all-content/alerts\n",
      "https://www.smh.com.au/topic/nsw-police-jdi\n",
      "https://www.smh.com.au/topic/sydney-crime-62n\n",
      "https://www.smh.com.au/topic/crime-5w4\n",
      "https://www.smh.com.au/topic/australian-federal-police-jnt\n",
      "https://www.9news.com.au/cyber-security\n",
      "https://www.9news.com.au/security\n",
      "https://www.rapid7.com/db/?q=&type=nexpose\n",
      "https://www.rapid7.com/db/?q=&type=nexpose&page=2\n",
      "https://www.rapid7.com/db/?q=&type=nexpose&page=3\n"
     ]
    }
   ],
   "source": [
    "# Main program\n",
    "urls = getUrls()\n",
    "for url in urls:\n",
    "    pHtml = urlReq(url)\n",
    "    if('cyber.gov.au' in url):\n",
    "        cga(pHtml)\n",
    "    if('smh' in url):\n",
    "        smh(pHtml, url)\n",
    "    if('9news' in url):\n",
    "        nine(pHtml, url)\n",
    "    if('rapid7' in url):\n",
    "        rapid(pHtml, url)\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
